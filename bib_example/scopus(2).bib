Scopus
EXPORT DATE: 06 May 2025

@ARTICLE{Bayram2025,
	author = {Bayram, Burcu and Meijer, David and Barumerli, Roberto and Spierings, Michelle and Baumgartner, Robert and Pomper, Ulrich},
	title = {Bayesian prior uncertainty and surprisal elicit distinct neural patterns during sound localization in dynamic environments},
	year = {2025},
	journal = {Scientific Reports},
	volume = {15},
	number = {1},
	doi = {10.1038/s41598-025-90269-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000353019&doi=10.1038%2fs41598-025-90269-9&partnerID=40&md5=20d95c1c6450881b28cf329b12678068},
	affiliations = {Department of Cognition, Emotion, and Methods in Psychology, Faculty of Psychology, University of Vienna, Vienna, Austria; Acoustics Research Institute, Austrian Academy of Sciences, Vienna, Austria; Department of Neurosciences, Biomedicine and Movement Sciences, University of Verona, Verona, Italy; Department of Behavioral and Cognitive Biology, University of Vienna, Vienna, Austria; Department of Animal Sciences, Institute for Biology Leiden, Leiden University, Leiden, Netherlands},
	abstract = {Estimating the location of a stimulus is a key function in sensory processing, and widely considered to result from the integration of prior information and sensory input according to Bayesian principles. A deviation of sensory input from the prior elicits surprisal, depending on the uncertainty of the prior. While this mechanism is increasingly understood in the visual domain, much less is known about its implementation in audition, especially regarding spatial localization. Here, we combined human EEG with computational modeling to study auditory spatial inference in a noisy, volatile environment and analyzed behavioral and neural patterns associated with prior uncertainty and surprisal. First, our results demonstrate that participants indeed used prior information during periods of stable environmental statistics, but showed evidence of surprisal and discarded prior information following environmental changes. Second, we observed distinct EEG activity patterns associated with prior uncertainty and surprisal in both the time- and time–frequency domain, which are in line with previous studies using visual tasks. Third, these EEG activity patterns were predictive of our participants’ sound localization error, response uncertainty, and prior bias on a trial-by-trial basis. In summary, our work provides novel behavioral and neural evidence for Bayesian inference during dynamic auditory localization. © The Author(s) 2025.},
	author_keywords = {Auditory; Bayesian inference; EEG; Localization; Neural oscillations; Perception; Prior uncertainty; Surprisal},
	keywords = {Acoustic Stimulation; Adult; Bayes Theorem; Electroencephalography; Female; Humans; Male; Sound Localization; Uncertainty; Young Adult; adult; article; computer model; controlled study; directional hearing; electroencephalogram; electroencephalography; environmental change; female; hearing; human; major clinical study; male; nerve cell; oscillation; perception; sensory processing; sensory stimulation; sound detection; uncertainty; auditory stimulation; Bayes theorem; physiology; uncertainty; young adult},
	correspondence_address = {B. Bayram; Department of Cognition, Emotion, and Methods in Psychology, Faculty of Psychology, University of Vienna, Vienna, Austria; email: burcu.bayram@univie.ac.at},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {40050310},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zeng2025,
	author = {Zeng, Shaoting and Chen, Liyi and Lan, Suihong},
	title = {Research on the extension of respiratory interaction modalities in virtual reality technology and innovative methods for healing anxiety disorders},
	year = {2025},
	journal = {Scientific Reports},
	volume = {15},
	number = {1},
	doi = {10.1038/s41598-025-92419-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000350509&doi=10.1038%2fs41598-025-92419-5&partnerID=40&md5=4cfc68e0996c683f6cbcd11043deeb94},
	affiliations = {College of Art and Design, Beijing University of Technology, Beijing, 100124, China; Academy of Arts & Design, Tsinghua University, Beijing, 100084, China},
	abstract = {The timely alleviation and healing of anxiety is crucial for preventing anxiety disorders. This study explores innovative digital approaches for anxiety relief by integrating virtual reality (VR) and multimodal interaction theories and technologies with psychodrama therapy and breathing therapy from psychology. The research proposes an innovative method of breathing interaction based on olfactory interaction modalities and designs breathing interaction semantics aimed at anxiety healing through three types of breathing therapy. Using the Unreal Engine, VR gamified scenarios and interaction logic for levels were constructed, leading to the development of a multimodal immersive software interaction system and a prototype for VR hardware interaction that extends the breathing interaction modality. The effectiveness of the system for anxiety relief was validated through an EEG experiment involving 38 participants, supported by analysis of Topographic Maps, Band-Power Reports, ERP analysis, and qualitative data from the USE scale. This research confirms that the innovative integration of VR and breathing interaction modalities is effective for anxiety therapy, aiding users in promptly alleviating anxiety and simplifying the psychological healing process. © The Author(s) 2025.},
	author_keywords = {Anxiety therapy; Breath interaction; Multimodal interaction; Unreal engine; Virtual reality},
	keywords = {Adult; Anxiety Disorders; Electroencephalography; Female; Humans; Male; Respiration; Respiratory Therapy; Virtual Reality; Young Adult; adult; anxiety disorder; breathing; electroencephalography; female; human; male; procedures; respiratory care; therapy; virtual reality; young adult},
	correspondence_address = {S. Zeng; College of Art and Design, Beijing University of Technology, Beijing, 100124, China; email: sjmjzst@gmail.com},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {40050356},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}