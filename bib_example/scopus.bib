Scopus
EXPORT DATE: 06 May 2025

@ARTICLE{Chanpornpakdi2025,
	author = {Chanpornpakdi, Ingon and Wongsawat, Yodchanan and Tanaka, Toshihisa},
	title = {Partial face visibility and facial cognition: event-related potential and eye tracking investigation},
	year = {2025},
	journal = {Cognitive Neurodynamics},
	volume = {19},
	number = {1},
	doi = {10.1007/s11571-025-10231-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000802325&doi=10.1007%2fs11571-025-10231-3&partnerID=40&md5=9f64e282369046aca1d145de864eb0e8},
	affiliations = {Department of Electronic and Information Engineering, Tokyo University of Agriculture and Technology, Koganei-shi, Tokyo, 184–8588, Japan; Department of Biomedical Engineering, Mahidol University, Salaya, Nakhon Pathom, 73170, Thailand},
	abstract = {Face masks became a part of everyday life during the SARS-CoV-2 pandemic. Previous studies showed that the face cognition mechanism involves holistic face processing, and the absence of face features could lower the cognition ability. This is opposed to the experience during the pandemic, when people could correctly recognize faces, although the mask covered a part of the face. This paper clarifies the partial face cognition mechanism of the full and partial faces based on the electroencephalogram (EEG) and eye-tracking data. We observed two event-related potentials, P3a in the frontal lobe and P3b in the parietal lobe, as subcomponents of P300. The amplitude of both P3a and P3b were lowered when the eyes were invisible, and the amplitude of P3a evoked by the nose covered was larger than the full face. The eye-tracking data showed that 16 out of 18 participants focused on the eyes associated with the EEG results. Our results demonstrate that the eyes are the most crucial feature of facial cognition. Moreover, the face with the nose covered might enhance cognition ability due to the visual working memory capacity. Our experiment also shows the possibility of people recognizing faces using both holistic and structural face processing. In addition, we calculated canonical correlation using the P300 and the total fixation duration of the eye-tracking data. The results show high correlation in the cognition of the full face and the face and nose covered (Rc=0.93) which resembles the masked face. The finding suggests that people can recognize the masked face as well as the full face in similar cognition patterns. © The Author(s) 2025.},
	author_keywords = {Face perception, Electroencephalogram (EEG), Event-related},
	keywords = {adult; anatomical concepts; Article; coronavirus disease 2019; correlation analysis; data processing; electroencephalogram; event related potential; eye tracking; facial recognition; female; frontal lobe; human; human experiment; male; neuroimaging; normal human; pandemic; parietal lobe; partial face visibility; vision; working memory},
	correspondence_address = {T. Tanaka; Department of Electronic and Information Engineering, Tokyo University of Agriculture and Technology, Tokyo, Koganei-shi, 184–8588, Japan; email: tanakat@cc.tuat.ac.jp},
	publisher = {Springer Science and Business Media B.V.},
	issn = {18714080},
	language = {English},
	abbrev_source_title = {Cogn. Neurodynamics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Cao2025,
	author = {Cao, Jiayi and Li, Bin and Li, Xiaoou},
	title = {Identification of Alzheimer’s disease brain networks based on EEG phase synchronization},
	year = {2025},
	journal = {BioMedical Engineering Online},
	volume = {24},
	number = {1},
	doi = {10.1186/s12938-025-01361-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000773718&doi=10.1186%2fs12938-025-01361-0&partnerID=40&md5=7b5d48059d6396310d716f4ad9e57d00},
	affiliations = {College of Medical Imaging, Shanghai University of Medicine & Health Sciences, Shanghai, 201318, China; College of Health Science and Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China; Shanghai Yangpu Mental Health Center, Shanghai, 200093, China},
	abstract = {Objective: Using the phase synchronization of EEG signals, two different phases, PLI and PLV, were used to construct brain network analysis and graph convolutional neural network, respectively, to achieve automatic identification of Alzheimer’s disease (AD) and to assist in the early diagnosis of Alzheimer’s disease. Methods: In this paper, we selected outpatients (16 AD subjects, 20 mild cognitive impairment (MCI) subjects and 21 healthy control (HC) subjects) from the outpatient clinic of Yangpu Mental Health Center in Shanghai, China, from January 2023 to December 2023, and collected resting-state EEG data. To collect resting-state EEG data, each patient was asked to sit down with eyes closed for 5 min. Firstly, the acquired EEG data were preprocessed to extract the data in the α-band at 8–13 Hz; secondly, the phase lag index (PLI) and phase-locked value (PLV) were used to construct the brain functional network, and the brain functional connectivity map was visualized by brain functional connectivity analysis. Finally, the constructed PLI and PLV were input into the graph convolutional neural network (GCN) model as node features for training and classification, respectively. Results: Healthy controls had relatively strong mean brain functional connectivity in the PLV brain network compared to AD and MCI patients. MCI patients showed lower mean brain functional connectivity in the brain network of PLI, while all three groups showed significant differences in brain functional connectivity between parietal and occipital lobes. The GCN model improved classification accuracy by more than 10% compared to using a machine learning classifier. When PLV was used as the nodal feature in the GCN model, the model achieved an average classification accuracy of 77.80% for the three groups of AD, MCI and HC, which was an improvement over the accuracy of choosing raw EEG data and PLI as the nodal feature. The performance of the model was further validated. Conclusions: The experimental results show that the GCN model can effectively identify the graph structure compared with the traditional machine learning model, the GCN-PLV model can better classify AD patients, and the alpha band is proved to be more suitable for AD resting-state EEG by tenfold cross-validation. The brain network map constructed based on PLI and PLV can further capture the local features of EEG signals and the intrinsic functional relationships between brain regions, and the combination of these two models has certain reference value for the diagnosis of AD patients. © The Author(s) 2025.},
	author_keywords = {Alzheimer’s disease; Cognitive impairment; Electroencephalogram; Functional connectivity},
	keywords = {Aged; Alzheimer Disease; Brain; Case-Control Studies; Cognitive Dysfunction; Electroencephalography; Electroencephalography Phase Synchronization; Female; Humans; Male; Middle Aged; Nerve Net; Neural Networks, Computer; Signal Processing, Computer-Assisted; Brain mapping; Convolutional neural networks; Graph neural networks; Image matching; Image segmentation; Neurodegenerative diseases; Patient rehabilitation; Alzheimer; Alzheimer’s disease; Brain networks; Cognitive impairment; Convolutional neural network; Functional connectivity; Healthy controls; Neural network model; Phase lags; Phase locked; adult; alpha rhythm; Alzheimer disease; Article; brain region; China; classification algorithm; controlled study; convolutional neural network; cross validation; data accuracy; data extraction; detection algorithm; early diagnosis; electroencephalogram; electroencephalography phase synchronization; feature detection; functional connectivity; graph convolutional neural network; human; major clinical study; middle aged; mild cognitive impairment; nerve cell network; neurologic examination; outpatient; outpatient department; resting state EEG; aged; Alzheimer disease; artificial neural network; brain; case control study; cognitive defect; diagnosis; electroencephalography; electroencephalography phase synchronization; female; male; nerve cell network; pathophysiology; signal processing; Electroencephalography},
	correspondence_address = {X. Li; College of Medical Imaging, Shanghai University of Medicine & Health Sciences, Shanghai, 201318, China; email: lixo@sumhs.edu.cn; B. Li; Shanghai Yangpu Mental Health Center, Shanghai, 200093, China; email: lib_23@sumhs.edu.cn},
	publisher = {BioMed Central Ltd},
	issn = {1475925X},
	coden = {BEOIB},
	pmid = {40059173},
	language = {English},
	abbrev_source_title = {Biomed. Eng. Online},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Yang2025,
	author = {Yang, Zengyao and Su, Qiruo and Xie, Jieren and Su, Hechong and Huang, Tianrun and Han, Chengcheng and Zhang, Sicong and Zhang, Kai and Xu, Guanghua},
	title = {Music tempo modulates emotional states as revealed through EEG insights},
	year = {2025},
	journal = {Scientific Reports},
	volume = {15},
	number = {1},
	doi = {10.1038/s41598-025-92679-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000728291&doi=10.1038%2fs41598-025-92679-1&partnerID=40&md5=5f6c2223a4f707e8a3a0a4ea0f224877},
	affiliations = {School of Mechanical Engineering, Xi’an Jiaotong University, Xi’an, 710049, China; State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, 710049, China; The First Affiliated Hospital of Xi’an Jiaotong University, Xi’an, China; Joint School of Design and Innovation, Xi’an Jiaotong University, Xi’an, 710049, China; Faillace Department of Psychiatry and Behavioral Sciences, McGovern Medical School, University of Texas Health Science Center at Houston, Houston, TX, United States},
	abstract = {Music can effectively influence human emotions, with different melodies and rhythms eliciting varying emotional responses. Among these, tempo is one of the most important parameters affecting emotions. This study explores the impact of music tempo on emotional states and the associated brain functional networks. A total of 26 participants without any history of neurological or psychiatric disorders and music training took part in the experiment, using classical piano music clips at different tempi (56, 106, 156 bpm) as stimuli. The study was conducted using emotional scales and electroencephalogram (EEG) analysis. The results showed that the valence level of emotions significantly increased with music tempo, while the arousal level exhibited a “V” shape relationship. EEG analysis revealed significant changes in brainwave signals across different frequency bands under different tempi. For instance, slow tempo induced higher Theta and Alpha power in the frontal region, while fast tempo increased Beta and Gamma band power. Moreover, fast tempo enhanced the average connectivity strength in the frontal, temporal, and occipital regions, and increased phase synchrony value (PLV) between the frontal and parietal regions. However, slow tempo improves PLV between the occipital and parietal regions. The findings of this study elucidate the effects of music tempo on the brain functional networks related to emotion regulation, providing a theoretical basis for music-assisted diagnosis and treatment of mood disorders. Furthermore, these results suggest potential applications in emotion robotics, emotion-based human-computer interaction, and emotion-based intelligent control. © The Author(s) 2025.},
	author_keywords = {Brain functional network; Electroencephalogram (EEG); Emotional States; Music; Tempo},
	keywords = {Acoustic Stimulation; Adult; Brain; Electroencephalography; Emotions; Female; Humans; Male; Music; Young Adult; adult; auditory stimulation; brain; electroencephalography; emotion; female; human; male; music; physiology; psychology; young adult},
	correspondence_address = {G. Xu; School of Mechanical Engineering, Xi’an Jiaotong University, Xi’an, 710049, China; email: ghxu@mail.xjtu.edu.cn},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {40065030},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Grootswagers2025,
	author = {Grootswagers, Tijl and Quek, Genevieve L. and Zeng, Zhen and Varlet, Manuel},
	title = {Human infant EEG recordings for 200 object images presented in rapid visual streams},
	year = {2025},
	journal = {Scientific Data },
	volume = {12},
	number = {1},
	doi = {10.1038/s41597-025-04744-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000802918&doi=10.1038%2fs41597-025-04744-z&partnerID=40&md5=7f4047110b5f5124e53beb3d96057b97},
	affiliations = {The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, Australia; School of Computer, Data, and Mathematical Sciences, Western Sydney University, Sydney, Australia; Department of Linguistics and Modern Languages, The Chinese University of Hong Kong, Sha Tin, Hong Kong; School of Psychology, Western Sydney University, Sydney, Australia},
	abstract = {Understanding the neural basis of human object recognition and semantic knowledge has been a significant area of exploration, with recent focus aiming to reveal the developmental trajectory of this core brain function. At present, however, there is limited access to high-quality neuroimaging data obtained from human infants. Addressing this gap, we present a dataset comprising electroencephalography responses from 42 human infants obtained in response to visual presentations of various objects. Leveraging a rapid serial visual presentation paradigm, 42 infants between 2 and 12 months of age viewed 200 images spanning 50 distinct objects, with as many repetitions as possible tailored to individual infants’ comfort. Our technical validation demonstrates discernible neural responses, affirming the dataset’s robustness and utility for exploring the neural underpinnings of visual object recognition in infancy. Building upon insights gained from adult studies, our findings suggest that fast presentation paradigms hold promise for efficiently capturing electrophysiological responses to a large array of visual stimuli in human infants. This dataset represents a valuable resource for advancing our understanding of the developmental trajectory of object recognition and semantic knowledge in the early stages of human life. © The Author(s) 2025.},
	keywords = {Brain; Electroencephalography; Humans; Infant; Pattern Recognition, Visual; Photic Stimulation; Visual Perception; brain; diagnostic imaging; electroencephalography; human; infant; photostimulation; physiology; vision; visual pattern recognition},
	correspondence_address = {T. Grootswagers; The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, Australia; email: t.grootswagers@westernsydney.edu.au},
	publisher = {Nature Research},
	issn = {20524463},
	pmid = {40057550},
	language = {English},
	abbrev_source_title = {Sci. Data},
	type = {Data paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}